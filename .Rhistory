polls_april <- str_detect(brexit_polls$startdate, pattern = "\\d\\d\\d\\d-04-\\d\\d")
count(polls_april)
length(polls_april)
polls_april == TRUE
is.true(polls_april)
sum(polls_april)
length(polls_april[polls_april == TRUE])
round_date(brexit_polls$enddate, unit="week", week_start = "2016-06-12")
week <- 2016-06-12
round_date(brexit_polls$enddate, unit="week",)
endweek <- round_date(brexit_polls$enddate, unit="week",)
str_detect(endweek, pattern = "week")
str_detect(brexit_polls$enddate, pattern = "week")
sum(round_date(brexit_polls$enddate, unit = "week") == "2016-06-12")
weekdays(brexit_polls$enddate, abbreviate = FALSE)
count(weekdays(brexit_polls$enddate, abbreviate = FALSE))
sum(weekdays(brexit_polls$enddate, abbreviate = FALSE))
weekdays <- weekdays(brexit_polls$enddate, abbreviate = FALSE)
count(weekdays)
group_by(weekdays)
table(weekdays)
data(movielens)
movielens%>%head
as_datetime(movielens$timestamp)
timerevi <- as_datetime(movielens$timestamp)
table(timerevi, decrease=TRUE)
table(timerevi)
movielens %>%
mutate(timestamp1 = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
year = format(timestamp1, "%Y")) %>%
count(year) %>%
arrange(desc(n))
mutate(timestamp1 = as_datetime(timestamp),
year = year(timestamp1)) %>%
group_by(year) %>%
summarise(n = n()) %>%
arrange(desc(n))
mutate(timestamp1 = as_datetime(timestamp),
year = year(timestamp1)) %>%
group_by(year) %>%
summarise(n = n()) %>%
arrange(desc(n))
library(lubridate)
movielens %>%
mutate(timestamp1 = as_datetime(timestamp),
year = year(timestamp1)) %>%
group_by(year) %>%
summarise(n = n()) %>%
arrange(desc(n))
library(lubridate)
movielens %>%
mutate(timestamp1 = as_datetime(timestamp),
time = time(timestamp1)) %>%
group_by(time) %>%
summarise(n = n()) %>%
arrange(desc(n))
movielens %>%
mutate(timest = as_datetime(timestamp),
time = time_format("%H:%M:%S", tz="UTC")) %>%
group_by(time) %>%
summarise(n=n())%>%
arrange(desc(n))
movielens %>%
mutate(timest = time_format(timestamp),
time = time(timest)) %>%
group_by(time) %>%
summarise(n=n())%>%
arrange(desc(n))
movielens %>%
mutate(timest = as_datetime(timestamp),
time = time(timest)) %>%
group_by(time) %>%
summarise(n=n())%>%
arrange(desc(n))
movielens %>%
mutate(timest = as_datetime(timestamp),
time = time(timest)) %>%
group_by(time_format(format="%H:%M:%S", tz="UTC")) %>%
summarise(n=n())%>%
arrange(desc(n))
movielens %>%
mutate(timestamp1 = as.POSIXct(timestamp, origin = "1970-01-01", tz = "UTC"),
hour = format(timestamp1, "%H")) %>%
count(hour) %>%
arrange(desc(n))
library(tidyverse)
library(gutenbergr)
library(tidytext)
options(digits = 3)
install.packages("gutenbergr")
library(tidyverse)
library(gutenbergr)
library(tidytext)
options(digits = 3)
gutenberg_metadata
str_detect(gutenberg_metadata$title, patter="Pride and Prejudice", negate=FALSE)
sum(str_detect(gutenberg_metadata$title, patter="Pride and Prejudice", negate=FALSE))
sum(str_detect(gutenberg_metadata$title, patter="Pride and Prejudice"))
gutenberg_metadata %>%
filter(str_detect(title, "Pride and Prejudice"))  %>%
summarise(n = n_distinct(gutenberg_id))
gutenberg_works()
gutenberg_works("Pride and Prejudice")
gutenberg_works(=="Pride and Prejudice")
gutenberg_works()
gutenberg_works(title=="Prime and Prejudice")
gutenberg_works(gutenberg_works$title=="Prime and Prejudice")
gutenberg_works$title
gutenberg_metadata$title
gutenberg_works(title =="Pride and Prejudice")%>%
count(gutenberg_metadata$gutenberg_id)
gutenberg_metadata %>%
filter(str_detect(title, "Pride and Prejudice"))
gutenberg_metadata %>%
gutenberg_works(filter(str_detect(title, "Pride and Prejudice")%>%
count(gutenberg_id)))
gutenberg_works()
gutenberg_works(filter(str_detect(title, "Pride and Prejudice")
)
)
gutenberg_works%>% filter(str_detect(title, "Pride and Prejudice"))
str_detect(gutenberg_works$title, "Pride and Prejudice")
gutenberg_works(title="Pride and Prejudice")%>%
count(gutenberg_id, sort=TRUE)
gutenberg_works(title=="Pride and Prejudice")%>%
count(gutenberg_id, sort=TRUE)
library(tidytext)
words <- gutenberg_download(1342)
words
count(words)
words <- gutenberg_download(1342, strip = TRUE)
words
countwords <- words %>% unnest_tokens(word, text)
head(countwords)
data("stop_words")
word_count <- countwords %>%
anti_join(stop_words, by ="word")%>%
mutate(word=str_extract(word, "[a-z']+"))%>%
count(title, word, sort=TRUE)
familiar_texts <- gutenberg_download(c(5, 1342), meta_fields = "title")
tokenized_words <- familiar_texts %>%
unnest_tokens(word, text)
head(tokenized_words)
data(stop_words)
head(stop_words)
word_counts <- tokenized_words %>%
anti_join(stop_words, by = "word") %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(title, word, sort = TRUE)
head(word_counts)
word_proportions <- word_counts %>%
group_by(title) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(title, proportion) %>%
drop_na
library(ggplot2)
word_proportions %>%
top_n(20, `Pride and Prejudice`) %>%
mutate(word = reorder(word, `Pride and Prejudice`)) %>%
ggplot(aes(word, `Pride and Prejudice`)) +
geom_col() +
xlab(NULL) +
coord_flip()
words <- gutenberg_download(1342)
words
count(word(words))
sapply(strsplit(words, " "), length)
library(sapply))
library(tidyverse)
library(sapply))
sapply(strsplit(words, " "), length)
str_count(words)
str_count(words, pattern= "")
words <- gutenberg_download(1342)
words
View(words)
View(words)
sapply(strsplit(words, " "), length
)
sapply(strsplit(words, "\\s+"), length)
stri_count(words,regex="\\S+")
words <- gutenberg_download(1342)
words
library(dplyr)
library(stringr)
library(tidytext)
tidy_book <- words %>%
unnest_tokens(word, text)
tidy_book
View(tidy_book)
pride_prejudice <- gutenberg_download(1342)
View(pride_prejudice)
View(pride_prejudice)
unnest_tokens(pride_prejudice)
unnest_tokens(pride_prejudice)
unnest_tokens(pride_prejudice['text'])
unnest_tokens(pride_prejudice[text])
tidy_book <- pride_prejudice %>%
unnest_tokens(word, text)
tidy_book <- pride_prejudice['text'] %>%
unnest_tokens(word, text)
View(tidy_book)
View(tidy_book)
cleaned_book <- tidy_books %>%
anti_join(get_stopwords())
cleaned_book <- tidy_book %>%
anti_join(get_stopwords())
install.packages('stopwords')
cleaned_book <- tidy_book %>%
anti_join(get_stopwords())
View(cleaned_book)
View(cleaned_book)
length(cleaned_book)
rows(cleaned_book)
nrows(cleaned_book)
dim(cleaned_book)
dim(tidy_book)
lapply(strsplit(pride_prejudice, "\\s+"), function(x)
x[!(duplicated(x) | duplicated(x,fromLast=TRUE))])
View(pride_prejudice)
View(pride_prejudice)
View(cleaned_book)
View(cleaned_book)
View(tidy_book)
View(tidy_book)
book <- gutenberg_download(1342)
words <- book %>%
unnest_tokens(word, text)
nrow(words)
print("hello, world")
install.packages(c("shiny", "leaflet"))
library(shiny)
library(leaflet)
r_colors <- rgb(t(col2rgb(colors()) / 255))
names(r_colors) <- colors()
ui <- fluidPage(
leafletOutput("mymap"),
p(),
actionButton("recalc", "New points"),
p(),
textOutput("coordinates")
)
server <- function(input, output, session) {
points <- eventReactive(input$recalc, {
points = cbind(rnorm(40) * 2 + 13, rnorm(40) + 48)
output$coordinates <- renderText({
points
})
return(points)
}, ignoreNULL = FALSE)
observeEvent(input$Map_shape_click, { # update the location selectInput on map clicks
output$coordinates <- renderText({
"You have selected this"
})
})
output$mymap <- renderLeaflet({
leaflet() %>%
addProviderTiles(providers$Stamen.TonerLite,
options = providerTileOptions(noWrap = TRUE)
) %>%
addMarkers(data = points())
})
}
shinyApp(ui, server)
install.packages("RMySQL", type = "source")
library("RMySQL", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.5")
library("RMySQL")
install.packages("sqldf")
install.packages("sqldf")
install.packages("BH")
install.packages("quantmod")
install.packages("nbconvertR")
install.packages("jsonlite")
install.packages("rmarkdown")
filename <- "Finalassigment.zip"
if (!file.exists(filename)){
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileurl, filename, method="curl")
}
# checking for folder
if (!file.exists("UCI dataset")) {
unzip(filename)
}
library(dplyr)
### **1. Merge the training and the test sets to create one data set.**
features <- read.table("UCI HAR Dataset/features.txt", col.names = c("n","functions"))
x_train <- read.table("UCI HAR Dataset/train/X_train.txt", col.names = features$functions)
x_test <- read.table("UCI HAR Dataset/test/X_test.txt", col.names = features$functions)
x <- rbind(x_train, x_test)
head(x)
y_train <- read.table("UCI HAR Dataset/train/y_train.txt", col.names = "code")
y_test <- read.table("UCI HAR Dataset/test/y_test.txt", col.names = "code")
y <- rbind(y_train, y_test)
head(y)
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
subject <- rbind(subject_train, subject_test)
head(subject)
## we merge all 3 dataset
datamerged <- cbind(subject, y, x)
head(datamerged)
### **2.Extracts only the measurements on the mean and standard deviation for each measurement.**
measurments <- datamerged %>% select(subject, code, contains("mean"), contains("std"))
head(measurments)
### **3. Uses descriptive activity names to name the activities in the data set**
activities <- read.table("UCI HAR Dataset/activity_labels.txt", col.names = c("code", "activity"))
measurments$code <- activities[measurments$code,2]
head(measurments)
### **4. Appropriately labels the data set with descriptive variable names.**
names(measurments)[2] = "activity"
names(measurments)<-gsub("Acc", "Accelerometer", names(measurments))
names(measurments)<-gsub("Gyro", "Gyroscope", names(measurments))
names(measurments)<-gsub("BodyBody", "Body", names(measurments))
names(measurments)<-gsub("Mag", "Magnitude", names(measurments))
names(measurments)<-gsub("^t", "Time", names(measurments))
names(measurments)<-gsub("^f", "Frequency", names(measurments))
names(measurments)<-gsub("tBody", "TimeBody", names(measurments))
names(measurments)<-gsub("-mean()", "Mean", names(measurments), ignore.case = TRUE)
names(measurments)<-gsub("-std()", "STD", names(measurments), ignore.case = TRUE)
names(measurments)<-gsub("-freq()", "Frequency", names(measurments), ignore.case = TRUE)
names(measurments)<-gsub("angle", "Angle", names(measurments))
names(measurments)<-gsub("gravity", "Gravity", names(measurments))
head(measurments)
### **5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.**
library(dplyr)
tidydataset <- measurments %>%
group_by(subject, activity)%>%
summarise_all(funs(mean))
write.table(tidydataset, "tidydataset.txt", row.name=FALSE)
head(tidydataset)
str(tidydataset)
getwd()
setwd("~/GitHub")
setwd("~/GitHub/EDA (Coursera)")
### Read data
data <- read.table("household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("~/household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("./household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("~ExData_plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("~/ExData_plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("C:\Users\gaby\Documents\GitHub\CourseraRepo\ExData_Plotting1\household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("~/ExData_Plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
### Read data
data <- read.table("C:/Users/gaby/Documents/GitHub/CourseraRepo/ExData_Plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
data <- subset(data, Date == "2007-02-01" | Date == "2007-02-02")
head(data)
datetime <- strptime(paste(data$Date,as.character(data$Time)),"%Y-%m-%d %H:%M:%S")
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red")
hist(data$Global_active_power,
xlab = "Global Active Power (kilowatts)",
col  = "red",
main = "Global Active Power")
library(lubridate)
## **Exploratory Data Anaysis**
### Read data
data <- read.table("C:/Users/gaby/Documents/GitHub/CourseraRepo/ExData_Plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
data$Date <- as.Date(data$Date,"%d/%m/%Y")
data <- subset(data, Date == "2007-02-01" | Date == "2007-02-02")
head(data)
library(tidyverse)
library(lubridate)
## **Plot 1**
### *histogram*
# Getting date and time
datetime <- strptime(paste(data$Date,as.character(data$Time)),"%Y-%m-%d %H:%M:%S")
# plot 1
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red")
data <- read.table("/ExData_Plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
data$Date <- as.Date(data$Date,"%d/%m/%Y")
data <- subset(data, Date == "2007-02-01" | Date == "2007-02-02")
# Getting date and time
date_time <- strptime(paste(data$Date,as.character(data$Time)),"%Y-%m-%d %H:%M:%S")
# plot 1
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red")
# plot 1
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
# **Plot 2**
plot(date_time, as.numeric(as.character(data$Global_active_power)),
type = "l", xlab = "", ylab = "Global Active Power (kilowatts)")
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(png, "plot1.png",
width  = 480,
height = 480)
dev.off()
plot1<-hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(plot1, "plot1.png",
width  = 480,
height = 480)
dev.off()
rm(list = ls())
plot1<-hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(plot1, "plot1.png",
width  = 480,
height = 480)
dev.off()
dev.copy(plot1.png, "plot1.png",
width  = 480,
height = 480)
plot1<-hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
plot1
dev.copy(png, "plot1.png",
width  = 480,
height = 480)
dev.off()
plot1<-hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
plot1
dev.copy(png, filename="plot1.png",
width  = 480,
height = 480)
dev.off();
### *histogram*
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(png, filename="plot1.png",
width  = 480,
height = 480)
dev.off()
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(png, filename="plot1.png",
width  = 480,
height = 480)
dev.off()
rm(list = ls())
## **Exploratory Data Anaysis**
### Read data
data <- read.table("C:/Users/gaby/Documents/GitHub/CourseraRepo/ExData_Plotting1/household_power_consumption.txt", sep = ";", header = TRUE)
data$Date <- as.Date(data$Date,"%d/%m/%Y")
data <- subset(data, Date == "2007-02-01" | Date == "2007-02-02")
head(data)
#### loading libraries
library(tidyverse)
library(lubridate)
# Getting date and time
date_time <- strptime(paste(data$Date,as.character(data$Time)),"%Y-%m-%d %H:%M:%S")
## **Plot 1**
### *histogram*
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(png, filename="plot1.png",
width  = 480,
height = 480)
dev.off()
setwd("~/GitHub/CourseraRepo/ExData_Plotting1")
hist(as.numeric(as.character(data$Global_active_power)),
main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "firebrick4")
dev.copy(png, filename="plot1.png",
width  = 480,
height = 480)
dev.off()
# **Plot 2**
plot(date_time, as.numeric(as.character(data$Global_active_power)),
type = "l", xlab = "", ylab = "Global Active Power (kilowatts)")
dev.copy(png, filename="plot2.png",
width  = 480,
height = 480)
dev.off()
# **Plot3**
plot(date_time, as.numeric(as.character(data$Sub_metering_1)),
type = "l", xlab = "", ylab = "Energy sub metering")
lines(date_time, as.numeric(as.character(data$Sub_metering_2)),
type = "l", col = "red")
lines(date_time, data$Sub_metering_3,
type = "l", col = "blue")
legend("topright", "(x,y)",
legend=c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"),
col=c("black", "red", "blue"), lty=1, cex = 0.6)
dev.copy(png, filename="plot3.png",
width  = 480,
height = 480)
dev.off()
# **Plot 4**
par(mfrow=c(2,2), mar = c(4,4,3,2)+0.1)
## *similar to plot 2*
plot(date_time, as.numeric(as.character(data$Global_active_power)),
type = "l", xlab = "", ylab = "Global Active Power")
## *voltage plot*
plot(date_time, as.numeric(as.character(data$Voltage)),
type = "l", xlab = "Date Time", ylab = "Voltage")
## *similar to plot 3*
plot(date_time, as.numeric(as.character(data$Sub_metering_1)),
type = "l", xlab = "", ylab = "Energy sub metering")
lines(datetime, as.numeric(as.character(data$Sub_metering_2)),
type = "l", col = "firebrick4")
lines(date_time, data$Sub_metering_3,
type = "l", col = "dodgerblue3")
legend("topright", "(x,y)",
legend=c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"),
col = c("gray10", "firebrick4", "dodgerblue3"), lty = 1, cex = 0.5, bty = "n")
## global reactive power plot
plot(date_time, as.numeric(as.character(data$Global_reactive_power)),
type = "l", xlab = "Date Time", ylab = "Global_reactive_power")
dev.copy(png, filename="plot4.png",
width  = 480,
height = 480)
dev.off()
